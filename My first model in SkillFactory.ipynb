{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d6d2a1",
   "metadata": {
    "id": "a4d6d2a1"
   },
   "source": [
    "# Here Ill try to convert images to TF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065a2b85",
   "metadata": {
    "executionInfo": {
     "elapsed": 3168,
     "status": "ok",
     "timestamp": 1645121324159,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "065a2b85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6cae2c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1645121328009,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "f6cae2c4",
    "outputId": "0eee4162-d83d-487a-bf01-88c821e2a66f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1f9924",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "error",
     "timestamp": 1645124487614,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "cc1f9924",
    "outputId": "a83b1c3f-09b4-4e64-a84d-4438cb8c82d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johnlennon/My Drive/Python/Doc_mentor/Doc_mentor/data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "data_dir = pathlib.Path(work_file_dir+'/data')\n",
    "my_class1 = list(data_dir.glob('data/train/bill/*'))\n",
    "my_class2 = list(data_dir.glob('data/train/upd/*'))\n",
    "test_class = list(data_dir.glob(f'{data_dir}/test/*'))\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(my_class1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707bcc0",
   "metadata": {
    "id": "6707bcc0"
   },
   "outputs": [],
   "source": [
    "# load image via tf.io\n",
    "img = tf.io.read_file(str(my_class1[0]))\n",
    "# img.set_shape([28, 28, 3])\n",
    "# convert to tensor (specify 3 channels explicitly since png files contains additional alpha channel)\n",
    "# set the dtypes to align with pytorch for comparison since it will use uint8 by default\n",
    "tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
    "# (384, 470, 3)\n",
    "# resize tensor to 224 x 224\n",
    "tensor = tf.image.resize(tensor, [224, 224])\n",
    "# (224, 224, 3)\n",
    "# add another dimension at the front to get NHWC shape\n",
    "input_tensor = tf.expand_dims(tensor, axis=0)\n",
    "# (1, 224, 224, 3)\n",
    "# transpose (224, 224, 3) -> (3, 224, 224)\n",
    "tensor = tf.transpose(tensor, perm=[2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c3a69",
   "metadata": {
    "id": "f11c3a69"
   },
   "outputs": [],
   "source": [
    "tf.shape(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557609bf",
   "metadata": {
    "id": "557609bf"
   },
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c8733",
   "metadata": {
    "id": "e03c8733"
   },
   "outputs": [],
   "source": [
    "str(my_class1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e7d5",
   "metadata": {
    "id": "7f63e7d5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(tf.transpose(tensor), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c143eba",
   "metadata": {
    "id": "5c143eba"
   },
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b7528",
   "metadata": {
    "id": "0c0b7528"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.flow_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4b990",
   "metadata": {},
   "source": [
    "# Train with \"flow_from_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yjdcy4Yq4Kua",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4648,
     "status": "ok",
     "timestamp": 1645124921106,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "yjdcy4Yq4Kua",
    "outputId": "6efc8e6a-a863-4468-b264-b87a96f7368b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stDTovBI4dVS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "error",
     "timestamp": 1645123180858,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "stDTovBI4dVS",
    "outputId": "4939fa83-175c-42fa-c365-91e65bb6e1b5"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/Python/Doc_mentor/Doc_mentor/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edff2ded",
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1645125437403,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "edff2ded"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c694f79",
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1645125026430,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "6c694f79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 15:48:54.075292: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-18 15:48:54.075543: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(150,150,3,), name=\"layer1\")) # первый скрытый слой\n",
    "model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128, activation='relu', name=\"layer2\")) # второй скрытый слой\n",
    "model.add(Dense(3, activation='softmax', name=\"output\")) # выходной слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44bd01b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1645125445009,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "44bd01b9",
    "outputId": "f18d4ccb-36ad-482d-d8e8-8d181d054d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 150, 150, 256)     1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5760000)           0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 128)               737280128 \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 737,281,539\n",
      "Trainable params: 737,281,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',  # минимизируем кросс-энтропию\n",
    "    optimizer='adam',  # так будет быстрее, позже узнаем что это :)\n",
    "    metrics=['accuracy']  # выводим процент правильных ответов\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfd8d2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1645125449995,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "fdfd8d2e",
    "outputId": "d78aeb00-90a7-4596-fb4d-1c9d5a37f470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 567 images belonging to 3 classes.\n",
      "Found 114 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        f'{data_dir}/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=5,\n",
    "        class_mode='binary')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        f'{data_dir}/val',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=5,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5b2fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5097,
     "status": "error",
     "timestamp": 1645125458234,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "df5b2fb8",
    "outputId": "956d1312-f341-410a-bc1c-d5a5e3c544c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 15:49:00.755851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-18 15:49:00.756003: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-18 15:49:00.863569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - ETA: 0s - loss: 139.7224 - accuracy: 0.4200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 15:50:25.896623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 88s 4s/step - loss: 139.7224 - accuracy: 0.4200 - val_loss: 1.1003 - val_accuracy: 0.1600\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 83s 4s/step - loss: 3.0677 - accuracy: 0.3600 - val_loss: 1.0990 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.0984 - accuracy: 0.2800 - val_loss: 1.1025 - val_accuracy: 0.2000\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 82s 4s/step - loss: 2.5015 - accuracy: 0.3300 - val_loss: 1.1009 - val_accuracy: 0.3200\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 72s 4s/step - loss: 1.5606 - accuracy: 0.4500 - val_loss: 1.1025 - val_accuracy: 0.2400\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 52s 2s/step - loss: 1.0968 - accuracy: 0.4100 - val_loss: 1.1100 - val_accuracy: 0.0800\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 69s 3s/step - loss: 5.0341 - accuracy: 0.3400 - val_loss: 1.1050 - val_accuracy: 0.3600\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 57s 3s/step - loss: 1.0959 - accuracy: 0.3500 - val_loss: 1.1039 - val_accuracy: 0.2800\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 96s 5s/step - loss: 3.0691 - accuracy: 0.4400 - val_loss: 1.1083 - val_accuracy: 0.2800\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 87s 4s/step - loss: 1.0915 - accuracy: 0.4600 - val_loss: 1.1131 - val_accuracy: 0.2400\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 92s 5s/step - loss: 1.1028 - accuracy: 0.3500 - val_loss: 1.1199 - val_accuracy: 0.1600\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 85s 4s/step - loss: 1.0928 - accuracy: 0.4200 - val_loss: 1.1075 - val_accuracy: 0.3200\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 76s 4s/step - loss: 1.0911 - accuracy: 0.4330 - val_loss: 1.1135 - val_accuracy: 0.2400\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 99s 5s/step - loss: 1.0891 - accuracy: 0.4800 - val_loss: 1.1063 - val_accuracy: 0.3200\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 93s 5s/step - loss: 1.0883 - accuracy: 0.4400 - val_loss: 1.1120 - val_accuracy: 0.2800\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 97s 5s/step - loss: 1.0937 - accuracy: 0.4000 - val_loss: 1.0894 - val_accuracy: 0.4800\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 54s 3s/step - loss: 1.0968 - accuracy: 0.3800 - val_loss: 1.1118 - val_accuracy: 0.2800\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 75s 4s/step - loss: 1.0886 - accuracy: 0.4300 - val_loss: 1.1099 - val_accuracy: 0.3200\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 95s 5s/step - loss: 4.8611 - accuracy: 0.3918 - val_loss: 1.0940 - val_accuracy: 0.3600\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.0910 - accuracy: 0.4000 - val_loss: 1.1335 - val_accuracy: 0.1200\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 95s 5s/step - loss: 1.0945 - accuracy: 0.3700 - val_loss: 1.1200 - val_accuracy: 0.2400\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 50s 2s/step - loss: 1.0829 - accuracy: 0.4536 - val_loss: 1.1440 - val_accuracy: 0.0400\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 1.0828 - accuracy: 0.4639 - val_loss: 1.1190 - val_accuracy: 0.2400\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 32s 2s/step - loss: 1.0963 - accuracy: 0.3400 - val_loss: 1.1148 - val_accuracy: 0.3200\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0969 - accuracy: 0.3600 - val_loss: 1.1073 - val_accuracy: 0.3200\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 31s 2s/step - loss: 1.0866 - accuracy: 0.4400 - val_loss: 1.1223 - val_accuracy: 0.2400\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 34s 2s/step - loss: 1.0906 - accuracy: 0.4000 - val_loss: 1.1122 - val_accuracy: 0.3200\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 31s 2s/step - loss: 1.0886 - accuracy: 0.4100 - val_loss: 1.1130 - val_accuracy: 0.3200\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0859 - accuracy: 0.4124 - val_loss: 1.1140 - val_accuracy: 0.2800\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 31s 2s/step - loss: 1.0925 - accuracy: 0.3800 - val_loss: 1.1200 - val_accuracy: 0.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c6ad730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd161b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f94c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:28:49.716898: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/saved_models/my_model2/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model v1\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "model.save('data/saved_models/my_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fddf806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model v2\n",
    "# always save your weights after training or during training\n",
    "model.save_weights('first_try.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c00fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "new_model = tf.keras.models.load_model(f'{data_dir}/saved_models/my_model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e62a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3138,
     "status": "ok",
     "timestamp": 1645123860818,
     "user": {
      "displayName": "Rusttm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfYfT-B3GI8i7iCwSmBG7cAcvB3wofZf5oNPfZag=s64",
      "userId": "09199224461542009084"
     },
     "user_tz": -180
    },
    "id": "793e62a7",
    "outputId": "fc3d4cdd-00aa-444f-a1e0-65019e235637"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for x,y in train_generator:\n",
    "    print(x.shape)\n",
    "    print(x[0].shape, y.shape)\n",
    "    print(x[1].shape, y.shape)\n",
    "    print(y)\n",
    "    print(len(x))\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722db2a",
   "metadata": {
    "id": "c722db2a"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c9386",
   "metadata": {
    "id": "3d5c9386"
   },
   "outputs": [],
   "source": [
    "my_np_array1 = np.array([[[1],[2],[3]],[[4],[5],[6]]], dtype=object)\n",
    "my_np_array2 = np.array([[[1],[2],[3]],[[4],[5],[6]]], dtype=object)\n",
    "my_np_array = my_np_array1 + my_np_array2\n",
    "np.shape(my_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f980ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(my_np_array1, my_np_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_np_array1.__add__(my_np_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_np_array = np.concatenate((my_np_array1, my_np_array2))\n",
    "np.shape(my_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb295c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[1],[2],[3]],[[4],[5],[6]]]\n",
    "\n",
    "b = np.array([a]+[a])\n",
    "np.shape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape([a])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413dd38f",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e218f",
   "metadata": {},
   "source": [
    "#### Test variant1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1206c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        f'{data_dir}/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=5,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d19bf9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johnlennon/My Drive/Python/Doc_mentor/Doc_mentor/data/test/202103_test_18.jpg')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class = list(data_dir.glob('test/*.jpg'))\n",
    "len(test_class)\n",
    "test_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cb25175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class = list(data_dir.glob('test/*.jpg'))\n",
    "img = tf.io.read_file(str(test_class[0]))\n",
    "# img.set_shape([28, 28, 3])\n",
    "# convert to tensor (specify 3 channels explicitly since png files contains additional alpha channel)\n",
    "# set the dtypes to align with pytorch for comparison since it will use uint8 by default\n",
    "tensor = tf.io.decode_image(img, channels=0, dtype=tf.dtypes.float32)\n",
    "# (384, 470, 3)\n",
    "# resize tensor to 224 x 224\n",
    "tensor = tf.image.resize(tensor, [150, 150])\n",
    "# (224, 224, 3)\n",
    "# add another dimension at the front to get NHWC shape\n",
    "input_tensor = tf.expand_dims(tensor, axis=0)\n",
    "# (1, 224, 224, 3)\n",
    "# transpose (224, 224, 3) -> (3, 224, 224)\n",
    "# tensor = tf.transpose(tensor, perm=[2, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5343a1f",
   "metadata": {},
   "source": [
    "##### tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9739308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077],\n",
       "       [0.37316987, 0.3241894 , 0.30264077]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.predict(test_generator)\n",
    "#plt.imshow(tf.transpose(tensor), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут ваш код Архитектуры сети\n",
    "# не забудьте 10 выходов с активацией softmax на выходном слое!\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(28*28,))) # первый скрытый слой\n",
    "model.add(Dense(128, activation='relu',)) # второй скрытый слой\n",
    "model.add(Dense(10, activation='softmax',)) # выходной слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57a4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "My first model in SkillFactory.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
